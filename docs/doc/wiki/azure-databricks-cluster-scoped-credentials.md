# Databricks Cluster Scope Credentials Explained

Create Date: Jun 5 2025

Create by: Smars Hu

## 1. What are Cluster Scope Credentials?

**Cluster Scope Credentials** refer to credentials for accessing external resources (such as Azure Storage Account) that are **directly configured in the Spark configuration of a Databricks cluster**, so that all notebooks connected to the cluster can automatically use these credentials to access the corresponding resources.

âœ… Common scenarios include:
- Reading ADLS Gen2 or Blob Storage data via Spark
- Unified management of Key Vault secrets
- Connecting to JDBC data sources

---

## 2. How to Implement: Where to Configure?

### âœ… Method 1: Cluster-level Configuration (Recommended)
Add the following configuration in the **â€œSpark Configâ€** section when creating a Databricks cluster:

```bash
spark.hadoop.fs.azure.account.auth.type.<storage-account>.dfs.core.windows.net OAuth
spark.hadoop.fs.azure.account.oauth.provider.type.<storage-account>.dfs.core.windows.net org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider
spark.hadoop.fs.azure.account.oauth2.client.id.<storage-account>.dfs.core.windows.net <application-id>
spark.hadoop.fs.azure.account.oauth2.client.secret.<storage-account>.dfs.core.windows.net {{secrets/<scope>/<key-name>}}
spark.hadoop.fs.azure.account.oauth2.client.endpoint.<storage-account>.dfs.core.windows.net https://login.microsoftonline.com/<tenant-id>/oauth2/token
```

You can also directly reference Azure Key Vault secrets in the cluster settings.

---

### âš ï¸ Method 2: Dynamic Configuration in Notebook (Temporary)

At the beginning of each notebook, write the following code:

```python
spark.conf.set("spark.hadoop.fs.azure.account.key.<storage-account>.blob.core.windows.net", "<access-key>")
```

or

```python
spark.conf.set("spark.hadoop.fs.azure.account.oauth2.client.secret.<storage-account>.dfs.core.windows.net", dbutils.secrets.get(scope="kv", key="sp-secret"))
```

---

## 3. Benefits of Cluster Scope Credentials

| Advantage            | Description                                                                                  |
| -------------------- | -------------------------------------------------------------------------------------------- |
| âœ… Centralized Security Management | Store credentials (such as client secret) in Azure Key Vault, use Databricks Secret Scope to call, no need to hardcode secrets in code |
| âœ… Simplified Notebook Code        | All notebooks connected to the cluster can automatically access storage resources, reducing repetitive configuration |
| âœ… Supports Least Privilege Control| Can control SP permissions via Azure AD + RBAC                                  |
| âœ… Easy Maintenance               | When updating credentials, just update the secret, no need to modify code        |

---

## 4. Suitable Scenarios

* Multiple users sharing a compute cluster (each running their own notebook)
* Multiple notebooks need to access the same data source
* Automated ETL jobs, avoiding sensitive information scattered in scripts

---

## 5. Recommended Configuration for Production

| Method                                 | Recommended | Reason                                                      |
| --------------------------------------- | ----------- | ----------------------------------------------------------- |
| **Set credentials in cluster Spark Config** | âœ… Yes      | Secure, centralized, reusable; with Secret Scope, secrets are not exposed |
| Set credentials in notebook                | âŒ No       | Easy to leak secrets, hard to maintain, every notebook needs repeated setup |
| Use Access Key                             | âš ï¸ Caution | Overly broad permissions, recommend using Service Principal + RBAC instead |
| Use SAS Token                              | âœ… Optional | Suitable for temporary access, not for long-term deployment |

---

## 6. Best Practice Summary

* âœ… Use **Service Principal + RBAC** for permission control
* âœ… Use **Databricks Secret Scope + Key Vault** to store sensitive credentials
* âœ… Configure **Spark Credential at the cluster level** for better security and maintainability
* âŒ Avoid hardcoding credentials in notebooks

---

## 7. Reference Example (OAuth + KeyVault)

```bash
spark.hadoop.fs.azure.account.auth.type.smarsstorageaccount0328.dfs.core.windows.net OAuth
spark.hadoop.fs.azure.account.oauth.provider.type.smarsstorageaccount0328.dfs.core.windows.net org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider
spark.hadoop.fs.azure.account.oauth2.client.id.smarsstorageaccount0328.dfs.core.windows.net <client-id>
spark.hadoop.fs.azure.account.oauth2.client.secret.smarsstorageaccount0328.dfs.core.windows.net {{secrets/kv-scope/sp-client-secret}}
spark.hadoop.fs.azure.account.oauth2.client.endpoint.smarsstorageaccount0328.dfs.core.windows.net https://login.microsoftonline.com/<tenant-id>/oauth2/token
```

---

## ğŸ“ Summary

> **Cluster Scope Credentials are the recommended approach for accessing cloud storage in production environments.** Combined with Service Principal and Key Vault, you can achieve secure, stable, and highly reusable data access configuration, avoiding the spread of sensitive information in notebooks.

---


# Databricks é›†ç¾¤ä½œç”¨åŸŸå‡­è¯ï¼ˆCluster Scope Credentialsï¼‰è¯¦è§£

## ä¸€ã€ä»€ä¹ˆæ˜¯ Cluster Scope Credentialsï¼Ÿ

**Cluster Scope Credentials** æŒ‡çš„æ˜¯å°†è®¿é—®å¤–éƒ¨èµ„æºï¼ˆå¦‚ Azure Storage Accountï¼‰çš„èº«ä»½å‡­è¯ï¼Œ**ç›´æ¥é…ç½®åœ¨ Databricks é›†ç¾¤çš„ Spark é…ç½®ä¸­**ï¼Œä»è€Œä½¿æ‰€æœ‰è¿æ¥è¯¥é›†ç¾¤çš„ notebook éƒ½å¯ä»¥è‡ªåŠ¨ä½¿ç”¨è¿™äº›å‡­è¯è®¿é—®å¯¹åº”èµ„æºã€‚

âœ… å¸¸è§åœºæ™¯åŒ…æ‹¬ï¼š
- é€šè¿‡ Spark è¯»å– ADLS Gen2ã€Blob Storage æ•°æ®
- ç»Ÿä¸€ç®¡ç† Key Vault å¯†é’¥
- è¿æ¥ JDBC æ•°æ®æº

---

## äºŒã€å®ç°æ–¹å¼ï¼šåœ¨å“ªé…ç½®ï¼Ÿ

### âœ… æ–¹æ³• 1ï¼šé›†ç¾¤å±‚é…ç½®ï¼ˆæ¨èï¼‰
åœ¨åˆ›å»º Databricks é›†ç¾¤æ—¶çš„ **â€œSpark Configâ€** åŒºåŸŸæ·»åŠ å¦‚ä¸‹é…ç½®ï¼š

```bash
spark.hadoop.fs.azure.account.auth.type.<storage-account>.dfs.core.windows.net OAuth
spark.hadoop.fs.azure.account.oauth.provider.type.<storage-account>.dfs.core.windows.net org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider
spark.hadoop.fs.azure.account.oauth2.client.id.<storage-account>.dfs.core.windows.net <application-id>
spark.hadoop.fs.azure.account.oauth2.client.secret.<storage-account>.dfs.core.windows.net {{secrets/<scope>/<key-name>}}
spark.hadoop.fs.azure.account.oauth2.client.endpoint.<storage-account>.dfs.core.windows.net https://login.microsoftonline.com/<tenant-id>/oauth2/token
```

ä½ ä¹Ÿå¯ä»¥ç›´æ¥åœ¨é›†ç¾¤è®¾ç½®ä¸­å¼•ç”¨ Azure Key Vault çš„ secretã€‚

---

### âš ï¸ æ–¹æ³• 2ï¼šNotebook ä¸­åŠ¨æ€é…ç½®ï¼ˆä¸´æ—¶ï¼‰

åœ¨æ¯ä¸ª notebook çš„å¼€å¤´å†™å¦‚ä¸‹ä»£ç ï¼š

```python
spark.conf.set("spark.hadoop.fs.azure.account.key.<storage-account>.blob.core.windows.net", "<access-key>")
```

æˆ–

```python
spark.conf.set("spark.hadoop.fs.azure.account.oauth2.client.secret.<storage-account>.dfs.core.windows.net", dbutils.secrets.get(scope="kv", key="sp-secret"))
```

---

## ä¸‰ã€é›†ç¾¤ä½œç”¨åŸŸå‡­è¯çš„å¥½å¤„

| ä¼˜ç‚¹               | è¯´æ˜                                                                              |
| ---------------- | ------------------------------------------------------------------------------- |
| âœ… å®‰å…¨é›†ä¸­ç®¡ç†         | å°†å‡­è¯ï¼ˆå¦‚ client secretï¼‰å­˜æ”¾äº Azure Key Vaultï¼Œé…åˆ Databricks Secret Scope è°ƒç”¨ï¼Œæ— éœ€å°†å¯†é’¥å†™å…¥ä»£ç  |
| âœ… ç®€åŒ– notebook ä»£ç  | æ‰€æœ‰è¿æ¥è¯¥é›†ç¾¤çš„ notebook å¯è‡ªåŠ¨è®¿é—®å­˜å‚¨èµ„æºï¼Œå‡å°‘é‡å¤é…ç½®                                              |
| âœ… æ”¯æŒæœ€å°æƒé™æ§åˆ¶       | å¯é€šè¿‡ Azure AD + RBAC æ§åˆ¶ SP æƒé™                                                    |
| âœ… æ˜“äºç»´æŠ¤           | æ›´æ¢å‡­è¯æ—¶åªéœ€æ›´æ–° secretï¼Œæ— éœ€ä¿®æ”¹ä»£ç                                                          |

---

## å››ã€é€‚åˆåœºæ™¯

* å¤šç”¨æˆ·å…±äº«ä¸€ä¸ªè®¡ç®—é›†ç¾¤ï¼ˆæ¯äººè¿è¡Œè‡ªå·±çš„ Notebookï¼‰
* å¤šä¸ª Notebook éœ€è¦è®¿é—®ç›¸åŒçš„æ•°æ®æº
* è‡ªåŠ¨åŒ– ETL ä½œä¸šï¼Œé¿å…æ•æ„Ÿä¿¡æ¯æ•£è½åœ¨è„šæœ¬ä¸­

---

## äº”ã€ç”Ÿäº§ç¯å¢ƒæ¨èé…ç½®æ–¹å¼

| æ–¹å¼                        | æ˜¯å¦æ¨è  | ç†ç”±                                 |
| ------------------------- | ----- | ---------------------------------- |
| **é›†ç¾¤ Spark Config ä¸­è®¾ç½®å‡­è¯** | âœ… æ¨è  | å®‰å…¨ã€é›†ä¸­ã€å¯å¤ç”¨ï¼Œç»“åˆ Secret Scope ä¸æš´éœ²æ•æ„Ÿä¿¡æ¯  |
| Notebook ä¸­è®¾ç½®å‡­è¯            | âŒ ä¸æ¨è | å®¹æ˜“æ³„éœ²å¯†é’¥ã€ä¸æ˜“ç»´æŠ¤ã€æ¯ä¸ª notebook éƒ½éœ€é‡å¤è®¾ç½®     |
| ä½¿ç”¨ Access Key             | âš ï¸ è°¨æ… | æƒé™è¿‡å¤§ï¼Œæ¨èæ”¹ç”¨ Service Principal + RBAC |
| ä½¿ç”¨ SAS Token              | âœ… å¯é€‰  | é€‚ç”¨äºä¸´æ—¶è®¿é—®åœºæ™¯ï¼Œä½†ä¸é€‚åˆé•¿æœŸéƒ¨ç½²                 |

---

## å…­ã€æœ€ä½³å®è·µå°ç»“

* âœ… ä½¿ç”¨ **Service Principal + RBAC** æ§åˆ¶æƒé™
* âœ… ä½¿ç”¨ **Databricks Secret Scope + Key Vault** å­˜å‚¨æ•æ„Ÿå‡­è¯
* âœ… åœ¨ **é›†ç¾¤å±‚ç»Ÿä¸€é…ç½® Spark Credential**ï¼Œæå‡å®‰å…¨æ€§ä¸å¯ç»´æŠ¤æ€§
* âŒ é¿å…æŠŠå‡­è¯å†™æ­»åœ¨ Notebook é‡Œ

---

## ä¸ƒã€å‚è€ƒç¤ºä¾‹ï¼ˆOAuth + KeyVaultï¼‰

```bash
spark.hadoop.fs.azure.account.auth.type.smarsstorageaccount0328.dfs.core.windows.net OAuth
spark.hadoop.fs.azure.account.oauth.provider.type.smarsstorageaccount0328.dfs.core.windows.net org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider
spark.hadoop.fs.azure.account.oauth2.client.id.smarsstorageaccount0328.dfs.core.windows.net <client-id>
spark.hadoop.fs.azure.account.oauth2.client.secret.smarsstorageaccount0328.dfs.core.windows.net {{secrets/kv-scope/sp-client-secret}}
spark.hadoop.fs.azure.account.oauth2.client.endpoint.smarsstorageaccount0328.dfs.core.windows.net https://login.microsoftonline.com/<tenant-id>/oauth2/token
```

---

## ğŸ“ æ€»ç»“

> **Cluster Scope Credentials æ˜¯åœ¨ç”Ÿäº§ç¯å¢ƒä¸­è®¿é—®äº‘å­˜å‚¨çš„æ¨èåšæ³•**ï¼Œç»“åˆ Service Principal å’Œ Key Vault å¯å®ç°å®‰å…¨ã€ç¨³å®šã€é«˜å¤ç”¨çš„æ•°æ®è®¿é—®é…ç½®ï¼Œé¿å…æ•æ„Ÿä¿¡æ¯åœ¨ notebook ä¸­ä¼ æ’­ã€‚